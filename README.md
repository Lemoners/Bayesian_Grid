# Efficient Imitation Learning Through Task Generation

## 1. Abstract

- Imitation Learning (IL) has provided general solutions to a variety of tasks, but such algorithms usually require a potentially large amount of expert-labeled data. Previous works have addressed this issue with active imitation learning (AIL), which focuses on only querying the most valuable state. However, one limitation of those works is that they ignore the difficulty of the expert to answer the queries, especially in the human expert scenario. To address this problem, we propose a method in the structure of the Teacher-Student framework, in order to efficiently sample training tasks while considering demonstration cost. We conduct experiments on the grid world environment, demonstrating that our algorithm improves the agent's performance over traditional random sampling methods.

## 2. Installation

1. **Create a new virtual environment (recommended)**

```shell
virtualenv -p python3 venv
source venv/bin/activate
# exit the virtualenv after usage
deactivate
```

2. **Install the package**

```shell
pip install -r requirements.txt
```

## 3. Usage

### 3.1. Repository structure

```shell
.
├── mygrid # package
│   └── mygrid
│       └── MiniGrid
│           ├── AE 					# VAE
│           ├── Agent 				# Network for IL.
│           ├── Discriminator		# Hand-crafted metric for evaluating grids.
│           ├── Generator			# Generator for generaing grids.
│           ├── Memory				# Memory for Gaussian Process.
│           └── Utils
└── scripts # training and evaluating scripts
    ├── evaluate_IL.py
    ├── evaluate_RL.py
    ├── train_IL.py
    ├── train_RL.py
    ├── train_vae.py
    └── visualize
        ├── coordinate_visualize_vae.py
        ├── video_bayes.py
        ├── visualize_bayes.py
        └── visualize_vae.py

15 directories
```

### 3.2. Scripts

- **`evaluate_IL.py`**: evaluate the performance of IL agents, pictures will be saved at `scripts/results/IL`.
- **`evaluate_RL.py`**:  evaluate the performance of RL agents, pictures will be saved at `scripts/results/RL`.
- **`train_IL.py`**: train IL agents, parameters will be saved at `scripts/data/model/IL`.
- **`train_RL.py`**: train RL agents, parameters will be saved at `scripts/data/model/RL`.
- **`train_vae.py`**: train VAE for parametrizing training task space, model will be saved at `mygrid/mygrid/MiniGrid/AE/model`.

#### 3.2.1. Visualize

- **`coordinate_visualize_vae.py`**: visualize the grids sampled from VAE through changing hidden variable z. Pictures will be saved at `scripts/pictures/coordinate`.
- **`video_bayes.py`**: visualize the grids generated during training, pictures will be saved at `scripts/pictures/bayes_video`, which can be converted to video through `ffmpeg -f image2 -i scripts/pictures/bayes_video/%10d.png bayes.avi`
- **`visualize_bayes.py`**: visualize the distribution of grids ***during training*** and compare it to grids 
  generated by `HardMazeGene` (with PCA). Pictures will be saved at `scripts/pictures/bayes_training_pictures`.
- **`visualize_vae.py`**: visualize the distribution of grids sampled through VAE and compare to grids generated by `MazeGene`. (testing environment)

### 3.3. Usage

```shell
# Install mygrid
pip install -e mygrid/

# Training VAE. (Make sure to train VAE before training IL agent with Bayesian Optmization)
python scripts/train_vae.py

# Training IL/RL agents.
python scripts/train_IL.py
# or
python scripts/train_RL.py

# Evaluate IL/RL agents.
python scripts/evaluate_IL.py
# or
python scripts/evaluate_RL.py
```

